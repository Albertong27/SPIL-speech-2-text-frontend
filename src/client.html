<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Speech to Text</title>

    <!-- tailwind -->
    <link href="./input.css" rel="stylesheet" />
    <link href="./output.css" rel="stylesheet" />

    <!-- font poppins and roboto mono -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
      rel="stylesheet"
    />

    <!-- font awesome -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css"
    />
  </head>

  <body class="font-poppins">
    <section class="flex">
      <!-- left side -->
      <div
        class="flex h-screen w-[35%] flex-col rounded-r-xl border-r-2 border-gray-300"
      >
        <div class="w-full">
          <!-- search bar -->
          <div class="h-[15vh]">
            <div
              class="z-50 flex h-[15vh] w-full items-center justify-center rounded-tr-xl px-10"
            >
              <label
                class="input input-bordered flex w-full items-center gap-2 rounded-lg"
              >
                <input type="text" class="grow" placeholder="Search" />
                <i class="fas fa-search fa-sm" style="color: #697079"></i>
              </label>
            </div>
          </div>

          <!-- transcription result -->
          <div class="h-[70vh] !overflow-auto">
            <div class="relative flex h-full flex-col justify-end">
              <div class="space-y-6 overflow-auto px-10" id="transcription">
                <div id="getDate"></div>
                <p>
                  <span class="font-semibold" id="final"></span>
                  <span class="text-gray-300" id="interim"></span>
                </p>
              </div>
            </div>
          </div>

          <div class="fixed bottom-0 h-[15vh] w-[35%] rounded-br-xl">
            <div class="flex h-[15vh] items-center justify-between px-10">
              <!-- start record -->
              <button
                class="btn btn-primary w-fit flex-none rounded-lg"
                id="startListening"
                onclick="startAndStopListening('start')"
              >
                <i
                  class="fa-solid fa-microphone fa-sm"
                  style="color: #ffffff"
                ></i>
                Start Listening
              </button>

              <div class="flex gap-2">
                <!-- stop record -->
                <button
                  class="btn btn-disabled btn-error hidden rounded-lg !text-white"
                  id="stopListening"
                  onclick="my_modal_1.showModal()"
                >
                  <i class="fa-solid fa-stop fa-sm" style="color: #ffffff"></i>
                  Stop
                </button>

                <!-- pause record -->
                <button
                  class="btn btn-info hidden rounded-lg !text-white"
                  id="pauseListening"
                  onclick="startAndStopListening('pause')"
                >
                  <i class="fa-solid fa-pause fa-sm" style="color: #ffffff"></i>
                  Pause
                </button>
                <p class="hidden" id="countdown">3:30:00</p>
              </div>

              <button
                class="btn btn-circle btn-outline btn-sm"
                onclick="scrollToBottom()"
              >
                <i class="fa-solid fa-angles-down"></i>
              </button>
            </div>
          </div>
        </div>
      </div>

      <!-- right side -->
      <div class="mx-auto flex w-[65%]" id="rideSide">
        <!-- time picker -->
        <div class="w-full">
          <div class="flex justify-between p-6 pb-4" id="formheight">
            <div class="flex gap-2">
              <input
                type="time"
                id="time_1"
                class="block w-fit rounded-lg border border-gray-300 bg-gray-50 p-2.5 text-sm leading-none text-gray-900 focus:border-blue-500 focus:ring-blue-500 dark:border-gray-600 dark:bg-gray-700 dark:text-white dark:placeholder-gray-400 dark:focus:border-blue-500 dark:focus:ring-blue-500"
                required
              />
              <input
                type="time"
                id="time_2"
                class="block w-fit rounded-lg border border-gray-300 bg-gray-50 p-2.5 text-sm leading-none text-gray-900 focus:border-blue-500 focus:ring-blue-500 dark:border-gray-600 dark:bg-gray-700 dark:text-white dark:placeholder-gray-400 dark:focus:border-blue-500 dark:focus:ring-blue-500"
                onchange="preview()"
                required
              />
              <div
                class="tooltip tooltip-right tooltip-open"
                data-tip="Refresh"
                onclick="preview()"
              >
                <button class="btn btn-square">
                  <i class="fa-solid fa-arrows-rotate"></i>
                </button>
              </div>
            </div>
            <button
              class="btn btn-outline btn-primary h-full w-fit min-w-[188px] rounded-lg"
              type="submit"
              onclick="summarize('/summarizer')"
              id="summarizeButton"
            >
              <i
                class="fa-solid fa-wand-magic-sparkles fa-sm !fill-neutral"
              ></i>
              Summarize with AI
            </button>
          </div>

          <!-- preview area -->
          <div class="flex">
            <div
              class="ml-6 h-[calc(100vh-88px-24px)] w-1/2 overflow-auto rounded-l-xl border-2 border-gray-300 p-6"
            >
              <p class="text-gray-400" id="preview">
                Transcription summary with selected time will appear here
              </p>
            </div>
            <!-- summary area -->
            <div
              class="mr-6 h-[calc(100vh-88px-24px)] w-1/2 overflow-auto rounded-r-xl border-2 border-l-0 border-gray-300 p-6"
            >
              <p class="text-gray-400" id="summary">
                Transcription summary with selected time will appear here
              </p>
            </div>
          </div>
        </div>
      </div>

      <!-- stop listening modal -->
      <dialog id="my_modal_1" class="modal">
        <div class="modal-box rounded-lg">
          <p class="py-4">Are you sure you want to "Stop Listening"?</p>
          <div class="modal-action">
            <form method="dialog" class="space-x-1">
              <button
                class="btn btn-outline btn-error btn-sm rounded-lg hover:!text-white"
                onclick="startAndStopListening('stop')"
              >
                Yes
              </button>
              <button class="btn btn-outline btn-sm rounded-lg">Cancel</button>
            </form>
          </div>
        </div>
      </dialog>
    </section>

    <!-- alert -->
    <div class="hidden" id="alert">
      <div class="hidden" id="onerror">
        <i class="fa-solid fa-triangle-exclamation"></i>
        <span
          >The WebSocket connection is error. Please contact
          administrator.</span
        >
      </div>
      <div class="hidden" id="onclose">
        <i class="fa-solid fa-triangle-exclamation"></i>
        <span>The WebSocket connection is closed. Please start again.</span>
      </div>
    </div>
  </body>
</html>

<script>
  const finalDiv = document.getElementById("final");
  const getDateDiv = document.getElementById("getDate");
  const interimDiv = document.getElementById("interim");
  const loadingDiv = `<span class="loading loading-spinner loading-md"></span>`;
  const onAlertDiv = document.getElementById("alert");
  const onCloseDiv = document.getElementById("onclose");
  const onErrorDiv = document.getElementById("onerror");
  const pauseListening = document.getElementById("pauseListening");
  const previewDiv = document.getElementById("preview");
  const startListening = document.getElementById("startListening");
  const stopListening = document.getElementById("stopListening");
  const summarizeButtonDiv = document.getElementById("summarizeButton");
  const summaryDiv = document.getElementById("summary");
  const transcriptionDiv = document.getElementById("transcription");
  let audioContext = null;
  let isAlreadyStart = false;
  let micProcessor = null;
  let micStream = null;
  let ws = null;

  async function preview() {
    previewDiv.innerHTML = loadingDiv;
    const end_datetime = document.getElementById("time_2").value;
    const start_datetime = document.getElementById("time_1").value;
    const today = new Date().toLocaleDateString("id-ID").replace(/\//g, "-");
    try {
      let formData = new FormData();
      formData.append("start_datetime", `${today} ${start_datetime}`);
      formData.append("end_datetime", `${today} ${end_datetime}`);
      const response = await fetch("http://localhost:8000/preview", {
        method: "POST",
        body: formData,
      });
      const result = await response.json();
      previewDiv.textContent = result.transcript;
      previewDiv.classList = "text-black";
    } catch (error) {
      console.error(error);
      previewDiv.innerHTML = `
      <p class="text-gray-400" id="preview">
        Transcription summary with selected time will appear here
      </p>
      `;
      onAlertDiv.className = "toast";
      onErrorDiv.className =
        "alert alert-error text-white flex gap-2 fill-white rounded-lg text-sm";
      setTimeout(() => {
        onAlertDiv.className = "hidden";
        onErrorDiv.className = "hidden";
      }, 5000);
    }
  }

  function scrollToBottom() {
    transcriptionDiv.scrollTop = transcriptionDiv.scrollHeight;
  }

  const handleWebSocketCloseOrError = async (
    messageClass,
    alertClass,
    type,
  ) => {
    interimDiv.innerHTML = "";
    onAlertDiv.className = "toast";
    alertClass.className = `alert ${messageClass} flex gap-2 fill-white rounded-lg text-sm`;

    setTimeout(() => {
      alertClass.className = "hidden";
      onAlertDiv.className = "hidden";
    }, 5000);

    if (type === "listen") {
      await cleanupAudioResources();
      handleStop();
      resetWebSocket();
    } else if (type === "summary") {
      previewDiv.innerHTML = `
      <p class="text-gray-400" id="preview">
        Transcription summary with selected time will appear here
      </p>
      `;
      summaryDiv.innerHTML = `
      <p class="text-gray-400" id="summary">
        Transcription summary with selected time will appear here
      </p>
      `;
      resetSummarizeButton();
    }
  };

  function resetSummarizeButton() {
    summarizeButtonDiv.innerHTML = `
    <i class="fa-solid fa-wand-magic-sparkles fa-sm !fill-neutral"></i>Summarize
    with AI
    `;
    summarizeButtonDiv.classList.remove("btn-disabled");
  }

  function summarize(slug) {
    const loadingSpinner = `<span class="loading loading-spinner loading-md"></span>`;
    summaryDiv.innerHTML = loadingSpinner;
    summarizeButtonDiv.classList.add("btn-disabled");
    summarizeButtonDiv.innerHTML = loadingSpinner;
    const socket = new WebSocket(`ws://localhost:8000${slug}`);

    socket.onopen = () => {
      const formatDate = (id) =>
        `${new Date().toLocaleDateString("id-ID").replace(/\//g, "-")} ${document.getElementById(id).value}`;
      socket.send(
        JSON.stringify({
          start_datetime: formatDate("time_1"),
          end_datetime: formatDate("time_2"),
        }),
      );
    };

    socket.onmessage = ({ data }) => {
      const response = JSON.parse(data);
      summaryDiv.innerHTML = response.summary;
      summaryDiv.classList = "text-black";
      resetSummarizeButton();
    };

    socket.onerror = () =>
      handleWebSocketCloseOrError(
        "alert-error text-white",
        onErrorDiv,
        "summary",
      );
    socket.onclose = () =>
      handleWebSocketCloseOrError(
        "alert-warning text-black",
        onCloseDiv,
        "summary",
      );
  }

  async function cleanupAudioResources() {
    micProcessor?.disconnect();
    micStream?.getTracks().forEach((track) => track.stop());
    await audioContext?.close();
    micProcessor = micStream = audioContext = null;
  }

  function resetWebSocket() {
    if (ws && ws.readyState === WebSocket.OPEN) ws.close();
    ws = null;
  }

  function handleStop() {
    startListening.classList.remove("hidden");
    startListening.innerHTML = `
    <i class="fa-solid fa-microphone fa-sm" style="color: #ffffff"></i> Start
    Listening
    `;
    stopListening.classList.add("hidden");
    pauseListening.classList.add("hidden");
  }

  function initWebSocket() {
    if (!ws) {
      ws = new WebSocket("ws://localhost:8000/aws-browser-transcribe");
      ws.onmessage = (event) => {
        const { data } = event;
        const isListening = data === "listening";
        const timestamp = new Date().toString().split(" GMT")[0];
        interimDiv.innerHTML = isListening
          ? `<span class="loading loading-dots loading-md text-gray-500"></span>`
          : "";
        if (!isListening) {
          const transcriptChar = JSON.parse(data);
          finalDiv.innerHTML += `
          <p>
            <span class="font-semibold">${transcriptChar.transcription}</span><br /><span
              class="text-xs text-gray-500"
              >${timestamp}</span
            >
          </p>
          <br />
          `;
        }
        scrollToBottom();
      };
    }

    ws.onerror = () =>
      handleWebSocketCloseOrError(
        "alert-error text-white",
        onErrorDiv,
        "listen",
      );
    ws.onclose = () =>
      handleWebSocketCloseOrError(
        "alert-warning text-black",
        onCloseDiv,
        "listen",
      );
  }

  async function initAudio() {
    if (!audioContext) {
      audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: 16000,
      });
    }
  }

  var countdownTime = 5;

  function formatTime(seconds) {
    const hrs = Math.floor(seconds / 3600);
    const mins = Math.floor((seconds % 3600) / 60);
    const secs = seconds % 60;

    return `${hrs.toString().padStart(1, "0")}:${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`;
  }

  const countdownElement = document.getElementById("countdown");
  var timer;

  function interval() {
    timer = setInterval(() => {
      if (countdownTime <= 0) {
        clearInterval(timer);
        startAndStopListening("stop_timeout");
      } else {
        countdownElement.textContent = formatTime(countdownTime);
        countdownTime--;
      }
    }, 1000);
  }

  async function startAndStopListening(command) {
    getDateDiv.innerHTML = `<div class="badge badge-ghost">${new Date().toString().split(" GMT")[0]}</div>`;
    if (command === "start") {
      interval();
      countdownTime = 5;
      countdownElement.classList.remove("hidden");
      startListening.classList.add("hidden");
      stopListening.classList.remove("btn-disabled", "hidden");
      pauseListening.classList.remove("hidden", "btn-disabled");
      try {
        if (!isAlreadyStart) {
          resetWebSocket();
          initWebSocket();
        }
        await cleanupAudioResources();
        await initAudio();
        micStream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        const source = audioContext.createMediaStreamSource(micStream);
        micProcessor = audioContext.createScriptProcessor(4096, 1, 1);
        source.connect(micProcessor);
        micProcessor.connect(audioContext.destination);

        micProcessor.onaudioprocess = (e) => {
          if (ws && ws.readyState === WebSocket.OPEN) {
            const inputData = e.inputBuffer.getChannelData(0);
            const samples = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
              samples[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7fff;
            }
            ws.send(samples.buffer);
          }
        };
      } catch (error) {
        console.error(error);
        await cleanupAudioResources();
      }
    } else if (command === "stop") {
      countdownTime = 5;
      clearInterval(timer);
      countdownElement.classList.add("hidden");
      isAlreadyStart = false;
      await cleanupAudioResources();
      resetWebSocket();
      handleStop();
    } else if (command === "stop_timeout") {
      countdownTime = 5;
      clearInterval(timer);
      countdownElement.classList.add("hidden");
      isAlreadyStart = false;
      await cleanupAudioResources();
      resetWebSocket();
      handleStop();

      // countdownTime = 5;
      countdownElement.classList.remove("hidden");
      startListening.classList.add("hidden");
      stopListening.classList.remove("btn-disabled", "hidden");
      pauseListening.classList.remove("hidden", "btn-disabled");
      try {
        if (!isAlreadyStart) {
          resetWebSocket();
          initWebSocket();
        }
        await cleanupAudioResources();
        await initAudio();
        micStream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        while (audioContext === null) {
          await initAudio();
        }
        const source = audioContext.createMediaStreamSource(micStream);
        micProcessor = audioContext.createScriptProcessor(4096, 1, 1);
        source.connect(micProcessor);
        micProcessor.connect(audioContext.destination);
        
        micProcessor.onaudioprocess = (e) => {
          if (ws && ws.readyState === WebSocket.OPEN) {
            const inputData = e.inputBuffer.getChannelData(0);
            const samples = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
              samples[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7fff;
            }
            ws.send(samples.buffer);
          }
        };
      } catch (error) {
        console.error(error);
        await cleanupAudioResources();
      }
      interval();
    } else if (command === "pause") {
      isAlreadyStart = true;
      micStream?.getTracks().forEach((track) => track.stop());
      micStream = null;
      startListening.classList.remove("hidden");
      startListening.innerHTML = `<i class="fa-solid fa-play fa-sm" style="color: #ffffff"></i>Continue Listening`;
      stopListening.classList.add("hidden");
      pauseListening.classList.add("hidden");
    }
  }
</script>
